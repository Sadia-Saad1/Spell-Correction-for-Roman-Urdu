{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ09KYJzZEQB"
   },
   "source": [
    "## Name: Sadia Saad\n",
    "## Email: sadiasaad2322@gmail.com\n",
    "i have used a file dataset-mini.txt for checking the program repearedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "pCc61YLU_BRV"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import nltk\n",
    "from nltk.probability import ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlEtNRp3ZsZD"
   },
   "source": [
    "# File Reading\n",
    "This cell reads the text file that will be used as our Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X3OZe6XjTo4p",
    "outputId": "c35fc32a-16f3-4047-9e3d-603ed2e2ccfb"
   },
   "outputs": [],
   "source": [
    "#with open('dataset-mini.txt','r') as f:\n",
    "with open('data.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "data = \"\"\n",
    "# Appending all the lines into a string\n",
    "for i in lines:\n",
    "    data+=i\n",
    "    \n",
    "data=data.split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETAk6y4IZ8BT"
   },
   "source": [
    "This cell below reads the misspellings.txt file it has a list of words and their misspellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "pQ3QWWxZWtha"
   },
   "outputs": [],
   "source": [
    "with open('misspellings.txt','r') as f:\n",
    "    \n",
    "    lines = f.readlines()\n",
    "misspelled = \"\"\n",
    "for i in lines:\n",
    "    misspelled+=i\n",
    "misspelled=misspelled.split('\\n')\n",
    "#misspelled\n",
    "# Create a dictionary \n",
    "# It stores the correct word as key\n",
    "# And the list of wrong words as its value.\n",
    "misspellings = {}\n",
    "firstRow = 1\n",
    "for row in misspelled:\n",
    "    \n",
    "      if firstRow:\n",
    "            firstRow = 0\n",
    "      \n",
    "      else:  \n",
    "            # Slice the string read according to commas and tabs\n",
    "            correct_word = row.split(',')[0]\n",
    "            wrong_words = row.split(',')[-1]\n",
    "            wrong_words = wrong_words[1:]\n",
    "            wrong_words_list = wrong_words.split('\\t')\n",
    "            misspellings[correct_word] = wrong_words_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQuecDOlae_v"
   },
   "source": [
    "# Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "aT_YL_Mgg2-l"
   },
   "outputs": [],
   "source": [
    "# this list has all the words appearing in the vocabulary\n",
    "# we read the string\n",
    "# take a line\n",
    "# split it\n",
    "# and append the words in the uni-grams list.\n",
    "\n",
    "unigrams = list()\n",
    "for i in range(len(data)):\n",
    "  words = data[i].split()\n",
    "  for j in range(len(words)):\n",
    "    w1 = words[j]\n",
    "    unigrams.append(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbHkjoxTa7Fl"
   },
   "source": [
    "The cell below counts the **number of occurences of a word** and stores this value as a vlaue againt the word in a dictionary.\n",
    "And the unique Words list has all the distinctive words that are actually keys of unigram_word_dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "vBy1e5UtQjec"
   },
   "outputs": [],
   "source": [
    "unigram_word_dictionary = {}\n",
    "for w in unigrams:\n",
    "  if unigram_word_dictionary.get(w):\n",
    "    unigram_word_dictionary[w] += 1\n",
    "  else:\n",
    "    unigram_word_dictionary[w] = 1\n",
    "global UniqueWords\n",
    "UniqueWords = unigram_word_dictionary.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pooMQlJLbgeZ"
   },
   "source": [
    "## Unigram Model for Characters\n",
    "Calculate count of characters existing in the vocabulary. Store it in a dictionary with **alphabets** as the key and **occurence** as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "mPAhu3FuYw0h"
   },
   "outputs": [],
   "source": [
    "# Make Unigrams for the Characters\n",
    "count_unigram_prob = {} # Empty dictionary \n",
    "for word in unigrams:\n",
    "  for alphabet in word:\n",
    "    if alphabet in count_unigram_prob: # If alphabet already exists in the dict\n",
    "      count_unigram_prob[alphabet] += 1  #Add 1 to the occurance\n",
    "    else: # If alphabet read for the first time\n",
    "      count_unigram_prob[alphabet] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gjmLqImcCIQ"
   },
   "source": [
    "## Bigram Model for Two Consecutive Words\n",
    "Calculate count of characters that appear consecutively in the vocabulary. Store it in the dictionary, where the key is a tuple having two alphabets and the value is the number of times the two characters appeared consecutively in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "VorGLvAPa80I"
   },
   "outputs": [],
   "source": [
    "# Make Bigrams for the Characters\n",
    "count_bigram = {} # Empty Dictionary\n",
    "for correctWord in unigrams:\n",
    "  correctWord = '#' + correctWord\n",
    "  for x in range(len(correctWord) - 1): \n",
    "    w1 = correctWord[x]\n",
    "    w2 = correctWord[x+1]\n",
    "    if tuple((w1,w2)) in count_bigram: # If tuple already exists in the dict\n",
    "      count_bigram[tuple((w1,w2))] += 1\n",
    "    else: # If the tuple is read for the first time\n",
    "      count_bigram[tuple((w1,w2))] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8gwC7dWczxY"
   },
   "source": [
    "## Probability of Occurance of a word\n",
    "It calculates the probability of a word using unigram word dictionary to return the probability of a word occuring in the corpus.\n",
    "Its actually **Prior Probability P(w)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "8iiWjz6qHiKj"
   },
   "outputs": [],
   "source": [
    "# Language Model\n",
    "# Train the Unigram model -> P(w)\n",
    "\n",
    "def UnigramProbabilities(word): \n",
    "    \n",
    "    if unigram_word_dictionary.get(word):\n",
    "        return unigram_word_dictionary[word]/float(len(unigrams)) # Divide the Occurance with total # of words\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4TLZ7ZhdPEv"
   },
   "source": [
    "# Error Model\n",
    "This model will be used to estimate the probability of typing x when w was\n",
    "intended.\n",
    "This error is modeled using character level insert, delete, transpose and substitute tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx1HkmWnddYh"
   },
   "source": [
    "Function EditOperation takes two parameters. w represents the correct word and x represents the typed word. Returns the operation and x, y coordinates to be added in the confusion matrix \n",
    "\n",
    "**Logic Used in the Code:** Compare len of two strings.if **diff ==1** then operation is **insert or delete**. If diff of **length == 0** then operation is a **transpose or substitute**.\n",
    "--- **For Transpose** Sort both words Compare them, if equal and the index of the misplaced word is **varied by 1** then it is transpose, else substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "sD4CSaNsca6U"
   },
   "outputs": [],
   "source": [
    "def EditOperations(w,x):\n",
    "  # If both words are different\n",
    "  if w != x:\n",
    "    w_list = list(w)\n",
    "    x_list = list(x)\n",
    "    # INSERT\n",
    "    if len(w) <= len(x) - 1:\n",
    "      Insert_found = 0\n",
    "      for j in range(len(x_list) - 1):\n",
    "        if x_list[j] != w_list[j] and j == 0:\n",
    "          break\n",
    "        if x_list[j] != w_list[j]:\n",
    "          Insert_found = 1\n",
    "          # The last letter of w is x and the current letter is y\n",
    "          x = w_list[j-1]\n",
    "          y = x_list[j]\n",
    "          break\n",
    "      if Insert_found:    \n",
    "        return \"insert\", x, y\n",
    "      else:\n",
    "        # Insert operation at the first index\n",
    "        if x_list[0] != w_list[0]:\n",
    "          return \"insert\", '#', x_list[0]\n",
    "        # Insert operation at the last index\n",
    "        else:\n",
    "          return \"insert\", w_list[-1], x_list[-1]\n",
    "\n",
    "    # DELETE\n",
    "    elif len(w) >= len(x) + 1:\n",
    "      Delete_found = 0\n",
    "      for i in range(len(w_list) - 1):\n",
    "        if x_list[i] != w_list[i] and i==0:\n",
    "          break\n",
    "        if x_list[i] != w_list[i]:\n",
    "          Delete_found = 1\n",
    "          x = w_list[i-1]\n",
    "          y = w_list[i]\n",
    "          break\n",
    "      if Delete_found:\n",
    "        \n",
    "        return \"delete\", x, y\n",
    "      else:\n",
    "        # Delete Operation at the first index\n",
    "        if x_list[0] != w_list[0]:\n",
    "          return \"delete\", '#', w_list[0]\n",
    "        else:\n",
    "          return 'delete', w_list[-2], w_list[-1]\n",
    "\n",
    "    elif len(w) == len(x): # Either substitute or transpose\n",
    "      copyW = copy.deepcopy(w)\n",
    "      copyX = copy.deepcopy(x)\n",
    "      # SUBSTITUTE\n",
    "      if sorted(copyW) != sorted(copyX):  \n",
    "        for i in range(len(w_list)):\n",
    "            if w_list[i] != x_list[i]:\n",
    "              return \"substitute\", x_list[i], w_list[i]\n",
    "      # TRANSPOSE\n",
    "      else:\n",
    "        istrans = 0\n",
    "        for a in range(len(x)-1):\n",
    "          if x[a] == w[a+1] and x[a+1] == w[a]: # Check if indexes swapped are consecutive\n",
    "            istrans = 1\n",
    "            break\n",
    "        if istrans:\n",
    "          for i in range(len(w_list)-1):\n",
    "            if w_list[i] != x_list[i]:\n",
    "              return \"transpose\", w_list[i], w_list[i+1] \n",
    "  else:\n",
    "    return \"same\", -1, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_-iWRFkfSL2"
   },
   "source": [
    "## Confusion Matrix\n",
    "Making the Confusion Matrices for Insert, Delete, Transpose and Substitute Tables. Using the EditOperation function to poplulate the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1_JxwoPWyM7",
    "outputId": "3281435c-976d-4879-f3c7-17a6f289ef9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Insert DataFrame...\n",
      "     a    b    c    d    e    f    g    h    i    j  ...    q    r    s    t  \\\n",
      "#  594  650  705  682  710  707  683  655  707  671  ...  744  713  691  718   \n",
      "a  548  693  644  652  662  641  656  608  577  629  ...  653  507  606  620   \n",
      "b   57   81   95   97   60   86   66   81   91   83  ...   95   85   97   96   \n",
      "c   55   64   69   66   58   67   68   31   58   63  ...   62   64   70   76   \n",
      "d   99  109  127  136   97  148  114  111   98  130  ...  126  120  131  125   \n",
      "e  273  298  248  230  235  272  270  267  267  277  ...  254  219  294  236   \n",
      "f   23   39   58   38   32   44   38   37   32   41  ...   43   35   36   40   \n",
      "g   56   88   88   80   74   74   74   58   80   91  ...   80   57   69   85   \n",
      "h  112  206  210  237  185  228  234  217  192  228  ...  249  226  222  219   \n",
      "i  229  254  259  252  250  246  248  261  244  288  ...  243  248  220  240   \n",
      "j   38   53   53   42   50   50   49   47   47   68  ...   48   47   47   40   \n",
      "k   88  123  119  136  113  110  137   93  102  124  ...  116  112  110  112   \n",
      "l  113  145  157  126  126  131  167  147  109  153  ...  133  132  143  134   \n",
      "m   79  127  146  124  109  124  125  114  107  126  ...  111  117  112  107   \n",
      "n  190  213  255  190  203  223  221  218  213  249  ...  214  243  214  199   \n",
      "o  173  199  188  182  187  172  213  155  187  202  ...  197  178  162  211   \n",
      "p   42   69   88   73   50   53   64   61   57   53  ...   69   55   53   64   \n",
      "q   17   12   23   13   25   17   23   17   10   22  ...   23   27   20   27   \n",
      "r  162  223  233  220  198  207  190  212  174  232  ...  218  203  190  212   \n",
      "s  147  178  182  179  166  206  186  164  169  189  ...  175  196  173  161   \n",
      "t  145  186  184  202  155  203  210  165  159  206  ...  187  171  207  192   \n",
      "u  126  115  132  119  123  114  120  120  112  129  ...  128   84   91  118   \n",
      "v   29   23   27   22   15   22   23   25   25   16  ...   27   19   27   18   \n",
      "w   17   34   35   38   50   39   37   31   35   43  ...   43   44   40   39   \n",
      "x    8    6    5    4    8    4    8    6    3    5  ...    7    8    6    8   \n",
      "y   50  108  100   94   88  117  103   89   75  108  ...   73   81   74   84   \n",
      "z   27   37   32   28   31   40   41   40   27   26  ...   38   31   41   36   \n",
      "\n",
      "     u    v    w    x    y    z  \n",
      "#  730  732  710  771  681  744  \n",
      "a  670  633  626  656  634  648  \n",
      "b   98   90  100   97   81   88  \n",
      "c   60   61   59   79   69   55  \n",
      "d  126  131  115  130  131  149  \n",
      "e  277  286  259  243  241  270  \n",
      "f   34   43   39   28   39   31  \n",
      "g   72   70   87   65   84   81  \n",
      "h  222  222  232  215  224  218  \n",
      "i  276  275  278  242  266  254  \n",
      "j   33   54   55   39   48   61  \n",
      "k  104  112  112  127   93  119  \n",
      "l  120  136  151  146  139  123  \n",
      "m  105  119  133  116  114  123  \n",
      "n  205  243  232  241  209  256  \n",
      "o  169  199  190  213  192  206  \n",
      "p   55   78   63   67   52   71  \n",
      "q   16   18   15   15   24   20  \n",
      "r  193  216  231  218  243  206  \n",
      "s  172  198  216  198  181  170  \n",
      "t  200  179  204  211  186  220  \n",
      "u  121  104  110  122  127  105  \n",
      "v   17   17   33   34   25   27  \n",
      "w   41   38   35   43   44   45  \n",
      "x    5    5    1    9    7    3  \n",
      "y   98   82  112  116  100   89  \n",
      "z   29   35   34   30   32   25  \n",
      "\n",
      "[27 rows x 26 columns]\n",
      "...Delete DataFrame...\n",
      "    a   b   c   d   e  f   g   h   i  j  ...  q   r   s   t   u  v  w  x   y  \\\n",
      "#  40  23  18  15  13  9   6  19  18  9  ...  5  15  27  20   8  4  2  0   0   \n",
      "a  14   9   8  16   2  3   9  15  11  3  ...  2  40   9  40   0  3  4  1  12   \n",
      "b  21   0   0   1   6  1   0   5   6  0  ...  0   5   0   0   6  0  0  0   0   \n",
      "c   5   0   0   0   6  0   0  21   2  0  ...  0   2   1   4   1  0  0  0   0   \n",
      "d  18   0   0   0  14  0   2   4  13  0  ...  0   0   1   0   4  0  1  0   1   \n",
      "e   6   1   8  12  14  1   3   6   3  1  ...  0  21   9   6   0  1  0  2   2   \n",
      "f   5   0   0   0   1  1   0   0   3  0  ...  0   2   1   0   2  0  0  0   0   \n",
      "g  15   2   0   0   3  0   2   7   6  0  ...  0   0   0   0   4  0  0  0   0   \n",
      "h  58   1   0   0  14  0   0   0  15  0  ...  0   3   0   3  12  0  1  0   2   \n",
      "i   4   2   5   7   1  2   2   1   0  1  ...  1  11  13  12   0  2  1  0   6   \n",
      "j  11   0   0   0   0  0   0   4   5  0  ...  0   0   1   0   5  0  1  0   0   \n",
      "k  17   0   0   0   7  0   0  14  10  0  ...  0   4   1   2   3  0  0  0   1   \n",
      "l  29   1   0   1  11  1   1   2  13  0  ...  1   0   0   1   1  0  2  1   4   \n",
      "m  33   1   0   2   4  0   0   2  10  1  ...  0   1   1   1   6  0  1  0   1   \n",
      "n  25   2   6  10   7  0  14   1   7  1  ...  1   1   4   9   2  1  1  0   3   \n",
      "o   2   2   1   7   2  0   2   0   1  1  ...  0  18   5   2   2  2  2  0   2   \n",
      "p   9   0   0   1   7  0   0   3   3  0  ...  0   7   1   0   3  0  0  0   1   \n",
      "q   1   1   0   0   1  0   0   0   1  0  ...  0   0   1   0   1  0  0  0   0   \n",
      "r  29   0   0   6  12  1   1   1  17  2  ...  0   2   3   3   3  1  0  0   7   \n",
      "s  23   1   1   0  16  0   0  19   7  0  ...  0   1   4  10   6  1  0  0   1   \n",
      "t  28   0   0   1  19  0   0   6  12  0  ...  2   7   1   1   5  1  2  0   3   \n",
      "u   0   4   1   5   1  0   1   4   1  1  ...  1  15   9   3   0  0  2  0   0   \n",
      "v   3   0   0   0   5  0   0   0   4  0  ...  0   0   0   0   0  0  0  0   0   \n",
      "w  15   1   0   1   1  0   0   1   3  0  ...  0   1   0   0   0  0  0  0   0   \n",
      "x   1   0   0   0   1  0   0   0   1  0  ...  0   0   0   0   0  0  0  0   0   \n",
      "y  11   0   0   2   4  0   0   0   2  0  ...  0   0   0   1   0  0  0  0   0   \n",
      "z   4   1   0   1   2  0   0   0   0  0  ...  0   1   0   0   0  0  0  0   1   \n",
      "\n",
      "   z  \n",
      "#  4  \n",
      "a  6  \n",
      "b  3  \n",
      "c  0  \n",
      "d  0  \n",
      "e  3  \n",
      "f  1  \n",
      "g  1  \n",
      "h  0  \n",
      "i  2  \n",
      "j  0  \n",
      "k  0  \n",
      "l  0  \n",
      "m  0  \n",
      "n  1  \n",
      "o  1  \n",
      "p  0  \n",
      "q  0  \n",
      "r  1  \n",
      "s  0  \n",
      "t  0  \n",
      "u  1  \n",
      "v  0  \n",
      "w  0  \n",
      "x  0  \n",
      "y  1  \n",
      "z  0  \n",
      "\n",
      "[27 rows x 26 columns]\n",
      "...Substitute DataFrame...\n",
      "     a   b   c    d    e   f   g    h    i   j  ...   q    r    s    t    u  \\\n",
      "#    0   0   0    0    0   0   0    0    0   0  ...   0    0    0    0    0   \n",
      "a    0  78  66  120  184  28  48  191  189  32  ...  15  193  145  160   99   \n",
      "b  642   0  65  116  248  24  61  196  252  25  ...  15  218  179  187  107   \n",
      "c  634  78   0  115  274  35  70  216  265  32  ...  13  210  193  183  120   \n",
      "d  639  85  68    0  303  37  69  201  245  40  ...  17  188  149  173  117   \n",
      "e  580  74  68  110    0  33  62  207  208  49  ...  17  214  156  164   95   \n",
      "f  645  79  63  118  255   0  78  227  253  44  ...  11  217  157  188   99   \n",
      "g  642  75  68   88  262  34   0  187  247  40  ...  16  212  160  179  118   \n",
      "h  613  91  59  103  246  28  61    0  262  30  ...  15  208  149  174  113   \n",
      "i  560  79  52   94  212  30  53  201    0  34  ...  16  191  165  162   96   \n",
      "j  627  81  57  138  242  34  77  199  248   0  ...  14  201  166  165  104   \n",
      "k  648  81  63   95  272  29  63  205  248  41  ...  14  224  159  183  102   \n",
      "l  638  74  76   99  288  18  82  209  235  21  ...   8  205  153  171  108   \n",
      "m  642  69  65  106  246  33  68  213  257  35  ...  15  193  164  175  103   \n",
      "n  659  79  51   98  251  26  53  196  236  35  ...  28  209  178  146   97   \n",
      "o  598  79  67  102  228  33  64  203  268  35  ...  14  194  175  193   96   \n",
      "p  628  76  57   96  238  26  66  213  244  34  ...  15  250  165  188  137   \n",
      "q  690  83  64  122  251  34  60  231  258  38  ...   0  229  162  179  108   \n",
      "r  610  69  43   97  276  28  66  197  221  23  ...  21    0  163  155  109   \n",
      "s  623  60  74  112  239  33  76  233  249  31  ...  13  177    0  141   98   \n",
      "t  623  75  64   96  260  33  65  191  263  25  ...  12  212  170    0  102   \n",
      "u  652  80  60  124  221  35  60  199  221  36  ...  17  189  176  180    0   \n",
      "v  701  95  79  125  298  37  77  193  260  41  ...   9  221  150  184  110   \n",
      "w  616  74  70  115  258  24  62  208  249  29  ...  20  221  164  190  121   \n",
      "x  614  90  81  139  239  38  83  201  296  46  ...  18  231  204  191  118   \n",
      "y  612  69  82   91  255  33  59  198  231  45  ...  17  205  148  165  107   \n",
      "z  660  86  73  105  260  42  63  231  276  47  ...   8  241  166  166  122   \n",
      "\n",
      "    v   w   x    y   z  \n",
      "#   0   0   0    0   0  \n",
      "a  17  30   1   73  26  \n",
      "b  24  28   5   85  31  \n",
      "c  19  30   4   91  30  \n",
      "d  17  30   2   83  22  \n",
      "e  18  29   4   79  28  \n",
      "f  17  40   5   85  29  \n",
      "g  19  30   3   89  27  \n",
      "h  26  39  10   83  36  \n",
      "i  18  39   3   74  29  \n",
      "j  11  34   4   96  32  \n",
      "k  15  26   4   83  22  \n",
      "l  22  27   3   80  30  \n",
      "m  16  32   3   76  20  \n",
      "n  17  34   6   77  30  \n",
      "o  24  30   4   69  28  \n",
      "p  16  42   3   75  25  \n",
      "q  13  36   9   93  30  \n",
      "r  13  33   4   76  24  \n",
      "s  21  24   5   80  29  \n",
      "t  16  31   3   77  30  \n",
      "u  15  30   4   87  31  \n",
      "v   0  42  12  109  31  \n",
      "w  18   0   1   96  34  \n",
      "x  19  50   0   90  32  \n",
      "y  16  25   1    0  31  \n",
      "z  22  36   3   78   0  \n",
      "\n",
      "[27 rows x 26 columns]\n",
      "...Transpose DataFrame...\n",
      "    a   b  c   d   e  f   g   h   i   j  ...  q   r   s   t   u  v  w  x   y  \\\n",
      "#   0   0  0   0   0  0   0   0   0   0  ...  0   0   0   0   0  0  0  0   0   \n",
      "a   0  20  4  15   5  8  16  21  29  10  ...  4  57  32  38   4  4  7  0  38   \n",
      "b  27   0  0   0   4  0   0  16   5   0  ...  0   5   1   1   7  0  0  0   0   \n",
      "c   9   0  0   0   4  0   0  38   3   0  ...  0   2   1   4   0  0  0  0   0   \n",
      "d  24   0  0   0  19  0   2   7  16   0  ...  0   3   1   1   3  1  0  0   2   \n",
      "e  10   0  1  13   0  2   3  12   1   2  ...  0  23  15  12   2  1  3  0   3   \n",
      "f   9   0  1   0   3  0   0   0   7   0  ...  0   1   1   2   2  0  0  0   0   \n",
      "g  14   0  0   0   8  0   0   9   2   0  ...  0   2   3   1   2  0  1  0   1   \n",
      "h  58   2  1   0  16  0   0   0  21   0  ...  1   3   1  11  13  0  1  0   4   \n",
      "i   6   4  8   8   4  2   2   1   0   4  ...  2  17  14  16   0  3  1  2   9   \n",
      "j  14   0  0   1   5  0   1   3   3   0  ...  0   0   0   0   5  0  0  0   0   \n",
      "k  27   1  1   0   5  0   0  27   9   0  ...  0   3   5   3   4  0  1  0   0   \n",
      "l  27   0  0   7  19  0   3   2  11   0  ...  1   0   3   8   5  0  1  0   2   \n",
      "m  33   1  0   0  15  0   1   2  14   1  ...  0   4   0   3   7  0  0  0   2   \n",
      "n  32   0  6  19  14  0  18   1   8   3  ...  0   1  10  16   1  0  1  0   8   \n",
      "o   1   1  3   7   2  2   3   2   4   3  ...  0  16   6  12   6  1  3  0   0   \n",
      "p  10   0  0   2   4  0   0   6   8   0  ...  0   4   1   0   1  0  0  0   1   \n",
      "q   4   0  0   0   2  0   0   0   2   0  ...  0   0   0   2   5  0  0  0   0   \n",
      "r  37   0  4   4  26  1   2   2  20   1  ...  1   0  11   9   4  1  4  0   2   \n",
      "s  33   1  1   1   4  0   0  24  12   0  ...  0   2   0  15   6  1  4  0   0   \n",
      "t  43   1  0   0  23  0   0  23  25   0  ...  0  11   2   0   8  0  1  0   2   \n",
      "u   2   8  1   4   4  1   3   0   1   2  ...  0  14   6   5   0  0  1  0   0   \n",
      "v   6   0  0   0   6  0   0   0   3   1  ...  0   0   1   0   1  0  1  0   0   \n",
      "w  15   0  0   0   1  0   0   1   3   0  ...  0   0   2   0   0  0  0  0   0   \n",
      "x   0   0  1   0   0  0   0   0   2   0  ...  1   0   0   0   0  0  0  0   1   \n",
      "y  18   2  0   0   8  0   0   0   1   0  ...  0   1   0   1   3  0  0  0   0   \n",
      "z  10   0  0   0   1  0   1   0   4   0  ...  1   1   0   1   1  0  0  0   1   \n",
      "\n",
      "   z  \n",
      "#  0  \n",
      "a  5  \n",
      "b  0  \n",
      "c  0  \n",
      "d  0  \n",
      "e  2  \n",
      "f  0  \n",
      "g  0  \n",
      "h  2  \n",
      "i  1  \n",
      "j  0  \n",
      "k  0  \n",
      "l  2  \n",
      "m  1  \n",
      "n  0  \n",
      "o  1  \n",
      "p  0  \n",
      "q  0  \n",
      "r  1  \n",
      "s  0  \n",
      "t  0  \n",
      "u  2  \n",
      "v  0  \n",
      "w  0  \n",
      "x  0  \n",
      "y  0  \n",
      "z  0  \n",
      "\n",
      "[27 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X labels for the DataFrames\n",
    "x_values = ['#','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "#Y labels for the DataFrames\n",
    "y_values = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "# Create dataframes for the confusion matrices\n",
    "# Insert DataFrame\n",
    "Insert_DF = pd.DataFrame(columns = y_values, index = x_values)\n",
    "Insert_DF.fillna(0, inplace = True) \n",
    "\n",
    "# Delete DataFrame\n",
    "Delete_DF = pd.DataFrame(columns = y_values, index = x_values)\n",
    "Delete_DF.fillna(0, inplace = True) \n",
    "\n",
    "# Substitue DataFrame\n",
    "Substitute_DF = pd.DataFrame(columns = y_values, index = x_values)\n",
    "Substitute_DF.fillna(0, inplace = True) \n",
    "\n",
    "#Transpose DataFrame\n",
    "Transpose_DF = pd.DataFrame(columns = y_values, index = x_values)\n",
    "Transpose_DF.fillna(0, inplace = True) \n",
    "\n",
    "\n",
    "for correctWord in misspellings:\n",
    "  # Populate the confusion matrices using the edit operations\n",
    "  for incorrectWord in misspellings[correctWord]:\n",
    "    editOperation, x, y = EditOperations(correctWord,incorrectWord)\n",
    "    if editOperation == 'insert':\n",
    "        Insert_DF[y][x] += 1\n",
    "    elif editOperation == 'delete':   \n",
    "        Delete_DF[y][x] += 1\n",
    "    elif editOperation == 'substitute':\n",
    "        Substitute_DF[y][x] += 1\n",
    "    elif editOperation == 'transpose':\n",
    "        Transpose_DF[y][x] += 1\n",
    "\n",
    "        \n",
    "        \n",
    "#..................................................\n",
    "\n",
    "# Now printing all the dataframes\n",
    "\n",
    "#...................................................\n",
    "\n",
    "print(\"...Insert DataFrame...\")\n",
    "print(Insert_DF)\n",
    "print(\"...Delete DataFrame...\")\n",
    "print(Delete_DF)\n",
    "print(\"...Substitute DataFrame...\")\n",
    "print(Substitute_DF)\n",
    "print(\"...Transpose DataFrame...\")\n",
    "print(Transpose_DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "NLOqR4cOhAf4"
   },
   "outputs": [],
   "source": [
    "def getCountBigram(i, j):\n",
    "  # Return the value against the tuple i, j in the count bigram\n",
    "  return (count_bigram[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "1PDAEZNYWwyB"
   },
   "outputs": [],
   "source": [
    "#Returns the number of character counts in the unigram calculated above \n",
    "# Count of individual alphabets in correct misspellings dictionary\n",
    "def getCountOfWi(character):\n",
    "    #NUMBER OF HASHES IN THE CORPUS IS EQUAL TO TOTAL NUMBER OF WORDS\n",
    "  if character == '#':\n",
    "    return len(unigrams)\n",
    "  \n",
    "  return count_unigram_prob[character] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_F3hlNGqhDI9"
   },
   "source": [
    "## Probability of a Word\n",
    "ProbabilityOfWord() takes the correct word and the typed word. Computes P(x|w) by using probability according to theformulas of Insert, Delete, Substitute, and Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "LnlJqgCtQP6j"
   },
   "outputs": [],
   "source": [
    "def ProbabilityOfWord(w,x):\n",
    "  operation, i, j = EditOperations(w,x)\n",
    "  if operation == 'insert':\n",
    "        \n",
    "        probability = Insert_DF[j][i]/getCountOfWi(i)\n",
    "    \n",
    "  elif operation == 'delete':\n",
    "    probability = Delete_DF[j][i]/getCountBigram(i,j)\n",
    "  elif operation == 'substitute':\n",
    "    probability = Substitute_DF[j][i]/getCountOfWi(j)\n",
    "  elif operation == 'transpose':\n",
    "    probability = Transpose_DF[j][i]/getCountBigram(i,j)\n",
    "  elif operation == 'same':\n",
    "    probability = 1\n",
    "  return probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "_qOU_XaejiMY"
   },
   "outputs": [],
   "source": [
    "# Function checks if two words have a transpose operation between them\n",
    "def isTranspose(w,x):\n",
    "  if sorted(w) == sorted(x):\n",
    "    for a in range(len(x)-1):\n",
    "      if x[a] == w[a+1] and x[a+1] == w[a]: # Checks if the alphabets were consecutive\n",
    "        return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFRoBBJ5h24e"
   },
   "source": [
    "## Levenshtein's Edit distance formula - to measure the difference between two sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "e9UU_PurefS4"
   },
   "outputs": [],
   "source": [
    "# Calculate the edit distance between the given and candidate word\n",
    "def EditDistance(w,x):\n",
    "  len_w = len(w)\n",
    "  len_x = len(x)\n",
    "  edits = [[0 for e in range(len_x + 1)] for u in range(len_w + 1)]\n",
    "  for i in range(len(w) + 1):\n",
    "    for j in range(len(x) + 1):\n",
    "      if i == 0:\n",
    "        edits[i][j] = j\n",
    "      elif j == 0:\n",
    "        edits[i][j] = i\n",
    "      elif w[i-1] == x[j-1]:\n",
    "        edits[i][j] = edits[i-1][j-1]\n",
    "      else:\n",
    "        edits[i][j] = 1 + min(edits[i-1][j], edits[i][j-1], edits[i-1][j-1])\n",
    "  return edits[len_w][len_x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmLYz0LWiPJf"
   },
   "source": [
    "# Candidate Words Generation\n",
    "Function CandidateWords, returns the candidate words with 1 edit distance with typed word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "r1jMliAqbTSq"
   },
   "outputs": [],
   "source": [
    "def CandidateWords(x):\n",
    "  candidateWords = []\n",
    "  zeroEditCandidate = []\n",
    "  # Check if the word exists in Vocab\n",
    "  if x in UniqueWords:\n",
    "    print(\"This word exists in the corpus.\")\n",
    "    #Return only that word.\n",
    "    zeroEditCandidate.append(x)\n",
    "    return zeroEditCandidate\n",
    "  \n",
    "  for correctWord in UniqueWords:\n",
    "    #first calculate edit distance\n",
    "    editDist = EditDistance(correctWord, x)\n",
    "    #TRANSPOSE = 2 SUBSTITUTIONS\n",
    "    isTrans = isTranspose(correctWord, x)\n",
    "    if isTrans:\n",
    "        editDist -= 1\n",
    "    if editDist == 1:    \n",
    "        candidateWords.append(correctWord)\n",
    "\n",
    "  availableCandidates = []\n",
    "  # in case the entire data is not read\n",
    "  for w in candidateWords:\n",
    "    try:\n",
    "        \n",
    "      p = UnigramProbabilities(w)\n",
    "      if p > 0:\n",
    "        availableCandidates.append(w)\n",
    "    except:\n",
    "      # garbage assignment\n",
    "      abc=1 \n",
    "\n",
    "  return availableCandidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA8hBSjwjAC7"
   },
   "source": [
    "# Selection Model Using ArgMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPkm2Pn2jDpt"
   },
   "source": [
    "ProbableWord takes typed word and returns the highest probability word. The P(x|w) is computed from ProbabilityOfWord function and theP(w) is computed from UnigramProbabilities.Product is stored in options with  candidate word as key prob as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "LuLp1h2XooCu"
   },
   "outputs": [],
   "source": [
    "\n",
    "#will suggest the word with the maximum probability\n",
    "\n",
    "def ProbableWord(x):    \n",
    "  candidates = CandidateWords(x)\n",
    "  options = {} # Dictionary\n",
    "  for w in candidates:\n",
    "    prob_xw = ProbabilityOfWord(w,x)  # P(x|w)\n",
    "    prob_w = UnigramProbabilities(w)  # P(w)\n",
    "    result = prob_xw * prob_w            #PRODUCT OF P(x|w) and P(w)\n",
    "    options[w] = result                  \n",
    "    print(\"Candidate: \", w, \" Probability: \", result)\n",
    "  if options:\n",
    "    max_prob_word = max(options, key=options.get)\n",
    "    return max_prob_word\n",
    "  else:\n",
    "    print(\"No Candidates Words are Found\")\n",
    "    return \"None\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9pQeUfGkLMt"
   },
   "source": [
    "# Testing the Model on Different Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJJZIGHvcsQg",
    "outputId": "82f04e8e-d9a9-4496-be39-92da0f1222e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate:  rahi  Probability:  5.714363459552975e-09\n",
      "Candidate:  raha  Probability:  3.4873490902134255e-08\n",
      "Candidate:  raho  Probability:  1.92977232130321e-09\n",
      "Candidate:  rakh  Probability:  4.2728016699037896e-10\n",
      "Candidate:  rahe  Probability:  3.8712884730063484e-09\n",
      "Candidate:  rahy  Probability:  2.607132517817285e-10\n",
      "Candidate:  rah  Probability:  1.5037833030451365e-10\n",
      "Candidate:  rak  Probability:  8.015991623582741e-12\n",
      "Candidate:  rashk  Probability:  4.8027012315556255e-11\n",
      "Candidate:  rahu  Probability:  2.8704346909959607e-11\n",
      "Candidate:  rank  Probability:  3.328832006705691e-11\n",
      "Candidate:  rack  Probability:  1.795824306765435e-11\n",
      "Candidate:  raak  Probability:  1.4278045606281783e-10\n",
      "Suggested Word:  raha\n"
     ]
    }
   ],
   "source": [
    "x = 'rahk'\n",
    "suggestion = ProbableWord(x)\n",
    "print(\"Suggested Word: \", suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tszCK6meCOC",
    "outputId": "c3e2b86f-8cae-4b55-d9cd-9ffb627b411d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate:  khan  Probability:  3.238659154419653e-10\n",
      "Candidate:  khel  Probability:  1.6765211328720068e-10\n",
      "Candidate:  hen  Probability:  2.7213032217948696e-10\n",
      "Candidate:  kher  Probability:  8.501583850857543e-10\n",
      "Candidate:  bhen  Probability:  3.802076497056538e-11\n",
      "Candidate:  kahen  Probability:  4.192184365321231e-12\n",
      "Candidate:  khena  Probability:  1.3619545816581951e-12\n",
      "Candidate:  then  Probability:  1.5123070740888624e-10\n",
      "Candidate:  kren  Probability:  9.250138408845782e-11\n",
      "Candidate:  when  Probability:  7.488843875369143e-11\n",
      "Candidate:  ehen  Probability:  3.7758291308943024e-11\n",
      "Candidate:  khun  Probability:  1.0195337573951256e-11\n",
      "Candidate:  ahen  Probability:  1.5579067311777295e-11\n",
      "Candidate:  rhen  Probability:  2.5132697864542174e-11\n",
      "Candidate:  khn  Probability:  3.3780497298110064e-12\n",
      "Candidate:  khet  Probability:  5.7665518053291964e-12\n",
      "Candidate:  khe  Probability:  2.1938990616075486e-11\n",
      "Candidate:  khon  Probability:  8.708830773444552e-12\n",
      "Candidate:  khin  Probability:  3.111632484219201e-12\n",
      "Candidate:  nhen  Probability:  5.1042090769487264e-12\n",
      "Candidate:  ekhen  Probability:  4.231345500905036e-12\n",
      "Candidate:  chen  Probability:  3.137850175457632e-12\n",
      "Candidate:  khne  Probability:  2.8414142697410746e-12\n",
      "Candidate:  rkhen  Probability:  9.89473230123888e-12\n",
      "Candidate:  ken  Probability:  9.750384087009842e-13\n",
      "Candidate:  phen  Probability:  1.2910299397677615e-12\n",
      "Suggested Word is:  kher\n"
     ]
    }
   ],
   "source": [
    "x = 'khen'\n",
    "suggestion = ProbableWord(x)\n",
    "print(\"Suggested Word is: \",suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUFIQeMIqbPg",
    "outputId": "dc310e32-1806-4e05-eb8a-3a97fd0f8f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate:  shukria  Probability:  2.7862602463549664e-11\n",
      "Candidate:  shukriya  Probability:  2.114156842941423e-09\n",
      "Suggested Word is:  shukriya\n"
     ]
    }
   ],
   "source": [
    "x = 'shukriay'   # This is a correct word so it should return the same word\n",
    "suggestion = ProbableWord(x)\n",
    "print(\"Suggested Word is: \",suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1fwhOlNnR_a",
    "outputId": "7016bd66-50cd-4ee4-ff82-2aeedae54207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate:  mukhtalif  Probability:  5.857331928530717e-09\n",
      "Candidate:  mukhtal  Probability:  7.06155658620652e-11\n",
      "Candidate:  mukhtari  Probability:  1.4218742217196345e-11\n",
      "Suggested Word is:  mukhtalif\n"
     ]
    }
   ],
   "source": [
    "x = 'mukhtali'      # This is a correct word so it should return the same word\n",
    "suggestion = ProbableWord(x)\n",
    "print(\"Suggested Word is: \",suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oxzverrnTKe",
    "outputId": "3e175199-db6a-4226-c3d1-f942b90bc852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Candidates Words are Found\n",
      "Suggested Word is:  None\n"
     ]
    }
   ],
   "source": [
    "#No candidate word will be found for this randomly created word\n",
    "x = 'abcdefghi'\n",
    "suggestion = ProbableWord(x)\n",
    "print(\"Suggested Word is: \",suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gqo37WBmgPk1",
    "outputId": "21dbd7ec-2476-4993-dbcd-b03c751e23d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate:  pakistan  Probability:  2.0166754158679666e-10\n",
      "Candidate:  pakistani  Probability:  1.4435020961288475e-10\n",
      "Suggested Word is:  pakistan\n"
     ]
    }
   ],
   "source": [
    "x = 'pakistain'\n",
    "suggestion = ProbableWord(x)\n",
    "print(\"Suggested Word is: \",suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcwhfMxFgTDH",
    "outputId": "d3e08cd7-030c-4694-c176-6541e5ebf448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate:  pichli  Probability:  2.2071845317137127e-10\n",
      "Candidate:  pichla  Probability:  2.0521141972672746e-08\n",
      "Candidate:  piche  Probability:  1.1965655696496032e-10\n",
      "Candidate:  pichle  Probability:  3.456409175080245e-11\n",
      "Candidate:  pichly  Probability:  1.7716282596503896e-11\n",
      "Candidate:  picha  Probability:  6.597268647891886e-12\n",
      "Candidate:  pichy  Probability:  1.8288928765313027e-12\n",
      "Candidate:  pich  Probability:  3.0889373655479026e-11\n",
      "Suggested Word is:  pichla\n"
     ]
    }
   ],
   "source": [
    "# Word does not return any candidate words\n",
    "# Returns 'None' i.e. no word found\n",
    "x = 'pichl'\n",
    "suggestion = ProbableWord(x)\n",
    "print(\"Suggested Word is: \",suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spell Correction for Roman Urdu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
